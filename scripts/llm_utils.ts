import * as https from 'https';
import { validateEngineData } from '../src/å¶åƒå¤§å¸ˆé—ªè€€è‰²å½©-é‡æ„/æˆ˜æ–—/å¼•æ“-NG/engineDataSchema';

// ============ é…ç½® ============
const CONFIG = {
  apiKey: process.env.GEMINI_API_KEY || 'gg-gcli-6MVWNwwsNxnJNTPF2-eZFCnSDHWdXQ_e-OBVgtWPM4g', // Fallback for testing
  baseUrl: 'https://gcli.ggchan.dev/v1/chat/completions',
  model: 'gemini-3-flash-preview',
  maxRetries: 3,
};

// ============ ç±»å‹å®šä¹‰ ============
interface LLMResponse {
  choices: {
    message: {
      content: string;
    };
  }[];
}

// ============ å·¥å…·å‡½æ•° ============

function sleep(ms: number) {
  return new Promise(resolve => setTimeout(resolve, ms));
}

/**
 * å‘é€ LLM è¯·æ±‚ (åŒ…å«æŒ‡æ•°é€€é¿é‡è¯•)
 */
async function postRequest(payload: any, retryCount = 0): Promise<LLMResponse> {
  return new Promise((resolve, reject) => {
    const url = new URL(CONFIG.baseUrl);
    const options = {
      hostname: url.hostname,
      path: url.pathname,
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        Authorization: `Bearer ${CONFIG.apiKey}`,
      },
      timeout: 60000, // 60s è¶…æ—¶
    };

    const req = https.request(options, res => {
      let data = '';
      res.on('data', chunk => (data += chunk));
      res.on('end', () => {
        if (res.statusCode && res.statusCode >= 200 && res.statusCode < 300) {
          try {
            const jsonResponse = JSON.parse(data);
            resolve(jsonResponse);
          } catch (e: any) {
            reject(new Error(`API Response JSON Parse Error: ${e.message}`));
          }
        } else {
          // é‡åˆ° 429 æˆ– 5xx é”™è¯¯å°è¯•é‡è¯•
          if ((res.statusCode === 429 || (res.statusCode && res.statusCode >= 500)) && retryCount < CONFIG.maxRetries) {
            console.log(`âš ï¸ API Error ${res.statusCode}. Retrying (${retryCount + 1}/${CONFIG.maxRetries})...`);
            setTimeout(
              () => {
                postRequest(payload, retryCount + 1)
                  .then(resolve)
                  .catch(reject);
              },
              2000 * Math.pow(2, retryCount),
            ); // æŒ‡æ•°é€€é¿
          } else {
            reject(new Error(`API Error: ${res.statusCode} - ${data}`));
          }
        }
      });
    });

    req.on('error', e => {
      if (retryCount < CONFIG.maxRetries) {
        console.log(`âš ï¸ Network Error. Retrying (${retryCount + 1}/${CONFIG.maxRetries})...`);
        setTimeout(
          () => {
            postRequest(payload, retryCount + 1)
              .then(resolve)
              .catch(reject);
          },
          2000 * Math.pow(2, retryCount),
        );
      } else {
        reject(e);
      }
    });

    req.write(JSON.stringify(payload));
    req.end();
  });
}

/**
 * è°ƒç”¨ LLM å¹¶è·å– JSON ç»“æœ
 */
export async function callLLM(messages: any[], temperature = 0.1): Promise<any> {
  const payload = {
    model: CONFIG.model,
    messages: messages,
    max_tokens: 4000,
    temperature: temperature,
    response_format: { type: 'json_object' }, // å¼ºåˆ¶ JSON
  };

  const response = await postRequest(payload);

  if (!response.choices || !response.choices[0] || !response.choices[0].message) {
    throw new Error('Invalid API response structure');
  }

  const content = response.choices[0].message.content;
  try {
    return JSON.parse(content);
  } catch (e) {
    throw new Error(`Failed to parse LLM response as JSON: ${content}`);
  }
}

/**
 * éªŒè¯å¹¶è‡ªåŠ¨ä¿®å¤ (Self-Correction Loop)
 * @param systemPrompt ç³»ç»Ÿæç¤ºè¯
 * @param userPrompt ç”¨æˆ·æç¤ºè¯
 * @param maxFixRetries æœ€å¤§ä¿®å¤å°è¯•æ¬¡æ•°
 */
export async function generateAndValidate(
  systemPrompt: string,
  userPrompt: string,
  maxFixRetries = 2,
): Promise<{ success: boolean; data?: any; error?: string }> {
  let messages = [
    { role: 'system', content: systemPrompt },
    { role: 'user', content: userPrompt },
  ];

  for (let i = 0; i <= maxFixRetries; i++) {
    try {
      if (i > 0) console.log(`ğŸ”„ Attempting fix (${i}/${maxFixRetries})...`);

      const result = await callLLM(messages);

      // æå– engine_data (å¦‚æœ LLM è¿”å›äº†åŒ…è£¹ç»“æ„)
      const engineData = result.engine_data || result;

      // Zod æ ¡éªŒ
      const validation = validateEngineData(engineData);

      if (validation.success) {
        return { success: true, data: engineData };
      } else {
        const errorMsg = JSON.stringify(validation.errors, null, 2);
        console.warn(`âŒ Validation Failed: ${errorMsg}`);

        // å°†é”™è¯¯åé¦ˆç»™ LLM
        messages.push({ role: 'assistant', content: JSON.stringify(result) });
        messages.push({
          role: 'user',
          content: `JSON Validation Failed. Please fix the following errors and return the corrected JSON:\n${errorMsg}`,
        });
      }
    } catch (e: any) {
      console.error(`âŒ LLM Call Failed: ${e.message}`);
      // ç½‘ç»œé”™è¯¯ç­‰é€šå¸¸ä¸å€¼å¾—è®© LLM ä¿®å¤ï¼Œç›´æ¥æŠ›å‡ºæˆ–é‡è¯•
      if (i === maxFixRetries) return { success: false, error: e.message };
    }
  }

  return { success: false, error: 'Exceeded max fix retries' };
}
